{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8895d0fe",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "## Step 1: Load and Sample the Dataset\n",
    "- Load the US Accidents dataset.\n",
    "- Sample to 10,000 rows for efficiency.\n",
    "- Display basic information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2557f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b7ac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate chunks: 77\n",
      "Rows to sample per chunk: 129\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 100000 rows, sampled 129 rows\n",
      "Processed chunk with 28394 rows, sampled 129 rows\n",
      "Sampled dataset saved to data/usa_traffic_accidents_sampled.csv\n",
      "Sampled Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 46 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   ID                     10000 non-null  object \n",
      " 1   Source                 10000 non-null  object \n",
      " 2   Severity               10000 non-null  int64  \n",
      " 3   Start_Time             10000 non-null  object \n",
      " 4   End_Time               10000 non-null  object \n",
      " 5   Start_Lat              10000 non-null  float64\n",
      " 6   Start_Lng              10000 non-null  float64\n",
      " 7   End_Lat                5635 non-null   float64\n",
      " 8   End_Lng                5635 non-null   float64\n",
      " 9   Distance(mi)           10000 non-null  float64\n",
      " 10  Description            10000 non-null  object \n",
      " 11  Street                 9983 non-null   object \n",
      " 12  City                   10000 non-null  object \n",
      " 13  County                 10000 non-null  object \n",
      " 14  State                  10000 non-null  object \n",
      " 15  Zipcode                9999 non-null   object \n",
      " 16  Country                10000 non-null  object \n",
      " 17  Timezone               9991 non-null   object \n",
      " 18  Airport_Code           9967 non-null   object \n",
      " 19  Weather_Timestamp      9837 non-null   object \n",
      " 20  Temperature(F)         9773 non-null   float64\n",
      " 21  Wind_Chill(F)          7472 non-null   float64\n",
      " 22  Humidity(%)            9761 non-null   float64\n",
      " 23  Pressure(in)           9800 non-null   float64\n",
      " 24  Visibility(mi)         9757 non-null   float64\n",
      " 25  Wind_Direction         9758 non-null   object \n",
      " 26  Wind_Speed(mph)        9263 non-null   float64\n",
      " 27  Precipitation(in)      7180 non-null   float64\n",
      " 28  Weather_Condition      9763 non-null   object \n",
      " 29  Amenity                10000 non-null  bool   \n",
      " 30  Bump                   10000 non-null  bool   \n",
      " 31  Crossing               10000 non-null  bool   \n",
      " 32  Give_Way               10000 non-null  bool   \n",
      " 33  Junction               10000 non-null  bool   \n",
      " 34  No_Exit                10000 non-null  bool   \n",
      " 35  Railway                10000 non-null  bool   \n",
      " 36  Roundabout             10000 non-null  bool   \n",
      " 37  Station                10000 non-null  bool   \n",
      " 38  Stop                   10000 non-null  bool   \n",
      " 39  Traffic_Calming        10000 non-null  bool   \n",
      " 40  Traffic_Signal         10000 non-null  bool   \n",
      " 41  Turning_Loop           10000 non-null  bool   \n",
      " 42  Sunrise_Sunset         9967 non-null   object \n",
      " 43  Civil_Twilight         9967 non-null   object \n",
      " 44  Nautical_Twilight      9967 non-null   object \n",
      " 45  Astronomical_Twilight  9967 non-null   object \n",
      "dtypes: bool(13), float64(12), int64(1), object(20)\n",
      "memory usage: 2.6+ MB\n",
      "None\n",
      "\n",
      "First 5 rows:\n",
      "          ID   Source  Severity                     Start_Time  \\\n",
      "0  A-3622139  Source1         2            2017-05-22 07:33:50   \n",
      "1  A-4479643  Source1         2            2022-04-13 13:13:52   \n",
      "2   A-270558  Source2         2            2017-01-14 10:17:23   \n",
      "3  A-6440144  Source1         2            2021-02-09 21:06:22   \n",
      "4  A-4302788  Source1         2  2022-09-23 15:21:04.000000000   \n",
      "\n",
      "                        End_Time  Start_Lat   Start_Lng    End_Lat  \\\n",
      "0            2017-05-22 13:33:50  47.684784 -122.183295  47.674916   \n",
      "1            2022-04-13 14:30:28  29.950098  -90.075788  29.950690   \n",
      "2            2017-01-14 10:46:42  29.671015  -95.355721        NaN   \n",
      "3            2021-02-09 23:14:52  34.656161  -92.412019  34.657567   \n",
      "4  2022-09-23 18:59:53.000000000  40.734553  -74.106887  40.739202   \n",
      "\n",
      "      End_Lng  Distance(mi)  ... Roundabout Station   Stop Traffic_Calming  \\\n",
      "0 -122.185312         0.688  ...      False   False  False           False   \n",
      "1  -90.075621         0.042  ...      False   False  False           False   \n",
      "2         NaN         0.010  ...      False   False  False           False   \n",
      "3  -92.412123         0.097  ...      False   False  False           False   \n",
      "4  -74.065727         2.179  ...      False   False  False           False   \n",
      "\n",
      "  Traffic_Signal Turning_Loop Sunrise_Sunset Civil_Twilight Nautical_Twilight  \\\n",
      "0          False        False            Day            Day               Day   \n",
      "1          False        False            Day            Day               Day   \n",
      "2          False        False            Day            Day               Day   \n",
      "3           True        False          Night          Night             Night   \n",
      "4          False        False            Day            Day               Day   \n",
      "\n",
      "  Astronomical_Twilight  \n",
      "0                   Day  \n",
      "1                   Day  \n",
      "2                   Day  \n",
      "3                 Night  \n",
      "4                   Day  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "\n",
      "Columns:\n",
      "['ID', 'Source', 'Severity', 'Start_Time', 'End_Time', 'Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Description', 'Street', 'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "chunk_size = 100000  # Read 100,000 rows at a time\n",
    "target_sample_size = 10000  # Total rows we want\n",
    "sampled_chunks = []  # To store sampled data\n",
    "\n",
    "# Calculate sampling fraction per chunk\n",
    "total_rows_approx = 7700000  # Approximate total rows in the dataset\n",
    "chunks_approx = total_rows_approx // chunk_size\n",
    "rows_per_chunk = target_sample_size // chunks_approx\n",
    "\n",
    "print(f\"Approximate chunks: {chunks_approx}\")\n",
    "print(f\"Rows to sample per chunk: {rows_per_chunk}\")\n",
    "\n",
    "# Read the dataset in chunks and sample\n",
    "for chunk in pd.read_csv('../data/US_Accidents_March23.csv', chunksize=chunk_size, low_memory=False):\n",
    "    # Sample rows from the chunk\n",
    "    if len(chunk) >= rows_per_chunk:\n",
    "        sampled_chunk = chunk.sample(n=rows_per_chunk, random_state=42)\n",
    "    else:\n",
    "        sampled_chunk = chunk  # If chunk is smaller than rows_per_chunk, take all rows\n",
    "    sampled_chunks.append(sampled_chunk)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Processed chunk with {len(chunk)} rows, sampled {len(sampled_chunk)} rows\")\n",
    "\n",
    "    # Stop if we have enough rows\n",
    "    if sum(len(c) for c in sampled_chunks) >= target_sample_size:\n",
    "        break\n",
    "\n",
    "# Combine sampled chunks\n",
    "df_sampled = pd.concat(sampled_chunks, ignore_index=True)\n",
    "\n",
    "# Trim to exact target size\n",
    "if len(df_sampled) > target_sample_size:\n",
    "    df_sampled = df_sampled.sample(n=target_sample_size, random_state=42)\n",
    "\n",
    "# Save the sampled dataset\n",
    "df_sampled.to_csv('../data/usa_traffic_accidents_sampled.csv', index=False)\n",
    "print(\"Sampled dataset saved to data/usa_traffic_accidents_sampled.csv\")\n",
    "\n",
    "# Load the sampled dataset\n",
    "df = pd.read_csv('../data/usa_traffic_accidents_sampled.csv')\n",
    "\n",
    "# Display info\n",
    "print(\"Sampled Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nColumns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13dccfa",
   "metadata": {},
   "source": [
    "## Step 2: Clean and Preprocess\n",
    "- Load the sampled dataset.\n",
    "- Handle missing values.\n",
    "- Convert data types and extract time features.\n",
    "- Infer lighting condition from Sunrise_Sunset.\n",
    "- Save the cleaned dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43870c03",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd7c0e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (%):\n",
      "End_Lng                  43.65\n",
      "End_Lat                  43.65\n",
      "Precipitation(in)        28.20\n",
      "Wind_Chill(F)            25.28\n",
      "Wind_Speed(mph)           7.37\n",
      "Visibility(mi)            2.43\n",
      "Wind_Direction            2.42\n",
      "Humidity(%)               2.39\n",
      "Weather_Condition         2.37\n",
      "Temperature(F)            2.27\n",
      "Pressure(in)              2.00\n",
      "Weather_Timestamp         1.63\n",
      "Sunrise_Sunset            0.33\n",
      "Airport_Code              0.33\n",
      "Astronomical_Twilight     0.33\n",
      "Nautical_Twilight         0.33\n",
      "Civil_Twilight            0.33\n",
      "Street                    0.17\n",
      "Timezone                  0.09\n",
      "Zipcode                   0.01\n",
      "Description               0.00\n",
      "City                      0.00\n",
      "Source                    0.00\n",
      "ID                        0.00\n",
      "Severity                  0.00\n",
      "Distance(mi)              0.00\n",
      "Start_Lng                 0.00\n",
      "Start_Time                0.00\n",
      "End_Time                  0.00\n",
      "Start_Lat                 0.00\n",
      "County                    0.00\n",
      "Amenity                   0.00\n",
      "Country                   0.00\n",
      "State                     0.00\n",
      "Bump                      0.00\n",
      "Crossing                  0.00\n",
      "Give_Way                  0.00\n",
      "Junction                  0.00\n",
      "Station                   0.00\n",
      "Roundabout                0.00\n",
      "Railway                   0.00\n",
      "No_Exit                   0.00\n",
      "Turning_Loop              0.00\n",
      "Traffic_Signal            0.00\n",
      "Traffic_Calming           0.00\n",
      "Stop                      0.00\n",
      "dtype: float64\n",
      "Cleaned dataset saved to data/usa_traffic_accidents_cleaned.csv\n",
      "Cleaned Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8812 entries, 0 to 9999\n",
      "Data columns (total 51 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   ID                     8812 non-null   object        \n",
      " 1   Source                 8812 non-null   object        \n",
      " 2   Severity               8812 non-null   int64         \n",
      " 3   Start_Time             8812 non-null   datetime64[ns]\n",
      " 4   End_Time               8812 non-null   object        \n",
      " 5   Start_Lat              8812 non-null   float64       \n",
      " 6   Start_Lng              8812 non-null   float64       \n",
      " 7   End_Lat                4530 non-null   float64       \n",
      " 8   End_Lng                4530 non-null   float64       \n",
      " 9   Distance(mi)           8812 non-null   float64       \n",
      " 10  Description            8812 non-null   object        \n",
      " 11  Street                 8799 non-null   object        \n",
      " 12  City                   8812 non-null   object        \n",
      " 13  County                 8812 non-null   object        \n",
      " 14  State                  8812 non-null   object        \n",
      " 15  Zipcode                8812 non-null   object        \n",
      " 16  Country                8812 non-null   object        \n",
      " 17  Timezone               8812 non-null   object        \n",
      " 18  Airport_Code           8812 non-null   object        \n",
      " 19  Weather_Timestamp      8812 non-null   object        \n",
      " 20  Temperature(F)         8776 non-null   float64       \n",
      " 21  Wind_Chill(F)          6510 non-null   float64       \n",
      " 22  Humidity(%)            8764 non-null   float64       \n",
      " 23  Pressure(in)           8797 non-null   float64       \n",
      " 24  Visibility(mi)         8790 non-null   float64       \n",
      " 25  Wind_Direction         8760 non-null   object        \n",
      " 26  Wind_Speed(mph)        8288 non-null   float64       \n",
      " 27  Precipitation(in)      6215 non-null   float64       \n",
      " 28  Weather_Condition      8812 non-null   object        \n",
      " 29  Amenity                8812 non-null   bool          \n",
      " 30  Bump                   8812 non-null   bool          \n",
      " 31  Crossing               8812 non-null   bool          \n",
      " 32  Give_Way               8812 non-null   bool          \n",
      " 33  Junction               8812 non-null   bool          \n",
      " 34  No_Exit                8812 non-null   bool          \n",
      " 35  Railway                8812 non-null   bool          \n",
      " 36  Roundabout             8812 non-null   bool          \n",
      " 37  Station                8812 non-null   bool          \n",
      " 38  Stop                   8812 non-null   bool          \n",
      " 39  Traffic_Calming        8812 non-null   bool          \n",
      " 40  Traffic_Signal         8812 non-null   bool          \n",
      " 41  Turning_Loop           8812 non-null   bool          \n",
      " 42  Sunrise_Sunset         8812 non-null   object        \n",
      " 43  Civil_Twilight         8791 non-null   object        \n",
      " 44  Nautical_Twilight      8791 non-null   object        \n",
      " 45  Astronomical_Twilight  8791 non-null   object        \n",
      " 46  Road_Condition         8812 non-null   object        \n",
      " 47  Day_of_Week            8812 non-null   object        \n",
      " 48  Hour                   8812 non-null   float64       \n",
      " 49  Month                  8812 non-null   object        \n",
      " 50  Light_Condition        8812 non-null   object        \n",
      "dtypes: bool(13), datetime64[ns](1), float64(13), int64(1), object(23)\n",
      "memory usage: 2.7+ MB\n",
      "None\n",
      "\n",
      "Sample features:\n",
      "           Start_Time Day_of_Week  Hour     Month      Weather_Condition  \\\n",
      "0 2017-05-22 07:33:50      Monday   7.0       May          Mostly Cloudy   \n",
      "1 2022-04-13 13:13:52   Wednesday  13.0     April  Mostly Cloudy / Windy   \n",
      "2 2017-01-14 10:17:23    Saturday  10.0   January               Overcast   \n",
      "3 2021-02-09 21:06:22     Tuesday  21.0  February                 Cloudy   \n",
      "5 2022-05-28 16:48:00    Saturday  16.0       May                 Cloudy   \n",
      "\n",
      "  Road_Condition Light_Condition  \n",
      "0            Dry        Daylight  \n",
      "1            Dry        Daylight  \n",
      "2        Unknown        Daylight  \n",
      "3            Dry            Dark  \n",
      "5            Dry        Daylight  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the sampled dataset\n",
    "df = pd.read_csv('../data/usa_traffic_accidents_sampled.csv')\n",
    "\n",
    "# Check missing values\n",
    "print(\"Missing values (%):\")\n",
    "print((df.isnull().sum() / len(df) * 100).sort_values(ascending=False))\n",
    "\n",
    "# Drop rows with missing critical columns\n",
    "df = df.dropna(subset=['Start_Time', 'Start_Lat', 'Start_Lng', 'Weather_Condition'])\n",
    "\n",
    "# Infer Road_Condition from Weather_Condition and Precipitation(in)\n",
    "def infer_road_condition(row):\n",
    "    weather = str(row['Weather_Condition']).lower()\n",
    "    precipitation = row['Precipitation(in)'] if pd.notnull(row['Precipitation(in)']) else 0\n",
    "    \n",
    "    if 'rain' in weather or 'snow' in weather or 'ice' in weather or 'sleet' in weather or precipitation > 0:\n",
    "        return 'Wet'\n",
    "    elif 'clear' in weather or 'cloudy' in weather or 'fair' in weather:\n",
    "        return 'Dry'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df['Road_Condition'] = df.apply(infer_road_condition, axis=1)\n",
    "\n",
    "# Fill missing categorical columns\n",
    "df['Sunrise_Sunset'] = df['Sunrise_Sunset'].fillna('Unknown')\n",
    "df['City'] = df['City'].fillna('Unknown')\n",
    "df['State'] = df['State'].fillna('Unknown')\n",
    "\n",
    "# Convert Start_Time to datetime\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
    "\n",
    "# Extract time features\n",
    "df['Day_of_Week'] = df['Start_Time'].dt.day_name()\n",
    "df['Hour'] = df['Start_Time'].dt.hour\n",
    "df['Month'] = df['Start_Time'].dt.month_name()\n",
    "\n",
    "# Drop invalid datetime rows\n",
    "df = df.dropna(subset=['Start_Time'])\n",
    "\n",
    "# Infer Light_Condition from Sunrise_Sunset\n",
    "df['Light_Condition'] = df['Sunrise_Sunset'].map({'Day': 'Daylight', 'Night': 'Dark', 'Unknown': 'Unknown'})\n",
    "\n",
    "# Save cleaned dataset\n",
    "df.to_csv('../data/usa_traffic_accidents_cleaned.csv', index=False)\n",
    "print(\"Cleaned dataset saved to data/usa_traffic_accidents_cleaned.csv\")\n",
    "\n",
    "# Display info\n",
    "print(\"Cleaned Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nSample features:\")\n",
    "print(df[['Start_Time', 'Day_of_Week', 'Hour', 'Month', 'Weather_Condition', 'Road_Condition', 'Light_Condition']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6d8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
